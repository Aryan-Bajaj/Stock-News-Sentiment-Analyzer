# -*- coding: utf-8 -*-
"""Stock News Sentiment Analyzer .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-Sy763TxybRqzTLvnZOMa88M6VzGYJH8
"""

pip install newspaper3k

pip install GoogleNews

pip install nltk

import pandas as pd
import matplotlib.pyplot as plt
import datetime as dt
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from GoogleNews import GoogleNews
from newspaper import Article
from newspaper import Config
from wordcloud import WordCloud, STOPWORDS
from google.colab import files
import io

nltk.download('vader_lexicon')
nltk.download('STOPWORDS')

print('Importing Libraries ----- 100% Success')

now = dt.date.today()
now = now.strftime('%m-%d-%Y')
yesterday = dt.date.today() - dt.timedelta(days = 30)
yesterday = yesterday.strftime('%m-%d-%Y')
nltk.download('punkt') 
config = Config()
config.browser_user_agent = 'Mozilla/7.0 (Macintosh; Intel windos X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0'
config.request_timeout = 30
print('Configuring System ---- 100% Success')

name = input("Type the company Name : ")

if name != '':
    print(f'Searching & analyzing for {name}')

    #Scraping News with Google
    googlenews = GoogleNews(start=yesterday,end=now)
    googlenews.search(name)
    result = googlenews.result()

print('Searching & Analysing --- 100% Complete')

df = pd.DataFrame(result)
    df.head()

#df.to_csv('GOOGLEnewsOFcrudeOIL Without Summary.csv') 
#files.download('GOOGLEnewsOFcrudeOIL Without Summary.csv')

try:
    list =[]  
    for i in df.index:
        dict = {} #creating an empty dictionary to append an article in every single iteration
        article = Article(df['link'][i],config=config) 
        try:
          article.download() #downloading the article 
          article.parse() #parsing the article
          article.nlp() #performing natural language processing (nlp)
        except:
           pass 
        #storing results in our empty dictionary
        dict['Date']=df['date'][i] 
        dict['Media']=df['media'][i]
        dict['Title']=article.title
        dict['Article']=article.text
        dict['Summary']=article.summary
        dict['Key_words']=article.keywords
        list.append(dict)
    check_empty = not any(list)
    # print(check_empty)
    if check_empty == False:
      news_df=pd.DataFrame(list) #creating dataframe
      print(news_df)

except Exception as e:
    #exception handling
    print("Oops:" + str(e))
    print('There(s) some error with the company name, please try again' )


news_df.head()

#news_df.to_csv('GOOGLEnewsOFcrudeOIL With Summary.csv') 
#files.download('GOOGLEnewsOFcrudeOIL With Summary.csv')

news_df.info()

news_df.shape

#Sentiment Analysis
def percentage(part,whole):
    return 100 * float(part)/float(whole)

#Initial_Values
positive = 0
negative = 0
neutral = 0
#empty_lists
news_list = []
neutral_list = []
negative_list = []
positive_list = []

#news in the dataframe
for news in news_df['Summary']:
    news_list.append(news)
    analyzer = SentimentIntensityAnalyzer().polarity_scores(news)
    neg = analyzer['neg']
    neu = analyzer['neu']
    pos = analyzer['pos']
    comp = analyzer['compound']

    if neg > pos:
        negative_list.append(news) 
        negative += 1 
    elif pos > neg:
        positive_list.append(news) 
        positive += 1 
    elif pos == neg:
        neutral_list.append(news) 
        neutral += 1  

positive = percentage(positive, len(news_df)) 
negative = percentage(negative, len(news_df))
neutral = percentage(neutral, len(news_df))

#Converting_to_dataframe
news_list = pd.DataFrame(news_list)
neutral_list = pd.DataFrame(neutral_list)
negative_list = pd.DataFrame(negative_list)
positive_list = pd.DataFrame(positive_list)
#counting
print("Positive Sentiment:", '%.2f' % len(positive_list), end='\n')
print("Neutral Sentiment:", '%.2f' % len(neutral_list), end='\n')
print("Negative Sentiment:", '%.2f' % len(negative_list), end='\n')

print('Counting for',name,'---- 100% Completed')

# visualization
def word_cloud(text):
    stopwords = set(STOPWORDS)
    allWords = ' '.join([nws for nws in text])
    wordCloud = WordCloud(width = 2000, height = 1500,stopwords = stopwords,min_font_size = 10,max_font_size=100,colormap='Accent').generate(allWords)
    fig, ax = plt.subplots(figsize=(12,8))
    plt.imshow(wordCloud)
    ax.axis("off")
    fig.tight_layout(pad=0)
    plt.show()

print('Wordcloud Visualization is for ' + name)
word_cloud(news_df['Summary'].values)

#Visualizaion
labels = ['Positive ['+str(round(positive))+'%]' , 'Neutral ['+str(round(neutral))+'%]','Negative ['+str(round(negative))+'%]']
sizes = [positive, neutral, negative]
patches, texts = plt.pie(sizes,colors=['green', 'royalblue','red'], startangle=180)
plt.style.use('dark_background')
plt.legend(labels,loc='center')
plt.title(" News Analysis Result for : "+name+"" )
plt.axis('equal')
plt.show()